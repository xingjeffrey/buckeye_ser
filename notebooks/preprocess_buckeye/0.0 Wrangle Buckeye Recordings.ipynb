{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385677ad",
   "metadata": {},
   "source": [
    "# Wrangle Buckeye Ratings\n",
    "\n",
    "## Goal\n",
    "\n",
    "We need to find monologues from speakers that are in range with Anna's Corpus (16.855625 - 77.089875 secs).\n",
    "This entails iterating through each speaker, their tracks, and their turns, to identify segments that might fit the time restriction. Let's find their turns first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4886c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import buckeye\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0adf2be",
   "metadata": {},
   "source": [
    "## Find specific speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6189a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72037b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(turn):\n",
    "    '''\n",
    "    Trim the <> tokens from beginning and end of turns\n",
    "    return: trimmed_txt, front_trim, end_trim\n",
    "    '''\n",
    "        \n",
    "    front_cursor = 0\n",
    "    back_cursor = -1\n",
    "        \n",
    "    turn_list = turn.split(' ')\n",
    "        \n",
    "    try:## trim front\n",
    "        while (\"<\" in turn_list[front_cursor]):\n",
    "            front_cursor += 1\n",
    "            \n",
    "        while (\"<\" in turn_list[back_cursor]):\n",
    "            back_cursor -= 1\n",
    "    \n",
    "    except:\n",
    "        return [], turn_list[:front_cursor], []\n",
    "            \n",
    "    front_trim = turn_list[:front_cursor]    \n",
    "        \n",
    "    if back_cursor == -1:\n",
    "        trimmed_txt = turn_list[front_cursor:]\n",
    "        end_trim = []\n",
    "    else:\n",
    "        trimmed_txt = turn_list[front_cursor:back_cursor+1]\n",
    "        end_trim = turn_list[back_cursor+1:]\n",
    "        \n",
    "    #print(trimmed_txt, front_trim, end_trim)\n",
    "        \n",
    "    if trimmed_txt[-1] == '':\n",
    "        return trimmed_txt[:-1], front_trim, end_trim\n",
    "        \n",
    "    return trimmed_txt, front_trim, end_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7d2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_segments(track):\n",
    "    '''\n",
    "    Find segments of valid turns in a track\n",
    "    \n",
    "    input: \n",
    "    track\n",
    "    \n",
    "    output:\n",
    "    df containing turns and their time markers\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def get_symbol(word):\n",
    "        '''\n",
    "        Get a word and find entry/orthography\n",
    "        '''\n",
    "        try:\n",
    "            return word.orthography\n",
    "        except:\n",
    "            return word.entry\n",
    "    \n",
    "    def five_symbol_match(match_target, words):\n",
    "        '''\n",
    "        given a match_target list, find the positions of a three word match\n",
    "        '''\n",
    "        \n",
    "        pos = 0\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            try:\n",
    "                assert get_symbol(words[pos]) == match_target[0]\n",
    "                assert get_symbol(words[pos+1]) == match_target[1]\n",
    "                assert get_symbol(words[pos+2]) == match_target[2]\n",
    "                assert get_symbol(words[pos+3]) == match_target[3]\n",
    "                assert get_symbol(words[pos+4]) == match_target[4]\n",
    "                return {'strt':pos, 'end':pos+4}\n",
    "                \n",
    "            except:\n",
    "                pos += 1\n",
    "                if pos > len(words):\n",
    "                    raise Exception('No Match')\n",
    "            \n",
    "    turns = {\n",
    "        'words':[],\n",
    "        'strt':[],\n",
    "        'strt_t':[],\n",
    "        'end':[],\n",
    "        'end_t':[],\n",
    "        'utt':[],\n",
    "        'dur':[],\n",
    "        'word_max':[]\n",
    "    }\n",
    "    \n",
    "    ### iterate through each turn\n",
    "    for turn in track.txt:\n",
    "        \n",
    "        ## for each turn, trim it first\n",
    "        trimmed_turn, front_trim, end_trim = trim(turn)\n",
    "        #print(trimmed_turn)\n",
    "        \n",
    "        ## if turn has less than 10 symbols after trim, continue to next turn\n",
    "        if len(trimmed_turn) < 10:\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            try:\n",
    "                ## attempt to start 3 word symbol match\n",
    "                strt = five_symbol_match(trimmed_turn[:5], track.words)['strt'] ## make sure strt right place\n",
    "                end = five_symbol_match(trimmed_turn[-5:], track.words)['end'] ## make sure end right place\n",
    "\n",
    "                ## that the strt pointer is the first symbol of trimmed turn\n",
    "                assert get_symbol(track.words[strt]) == trimmed_turn[0] \n",
    "                ## that the end pointer is the end symbol of the trimmed turn\n",
    "                assert get_symbol(track.words[end]) == trimmed_turn[-1]\n",
    "\n",
    "                word_list = track.words[strt:end + 1]\n",
    "\n",
    "                assert trimmed_turn[0] == get_symbol(word_list[0])\n",
    "                assert trimmed_turn[-1] == get_symbol(word_list[-1])\n",
    "                \n",
    "                turns['words'].append(' '.join([get_symbol(word) for word in word_list]))\n",
    "                ## end symbol of trim should be the end symbol of whatever we added to words\n",
    "                turns['strt'].append(strt)\n",
    "                turns['strt_t'].append(track.words[strt].beg)\n",
    "                turns['end'].append(end)\n",
    "                turns['end_t'].append(track.words[end].end)\n",
    "                turns['utt'].append(len(word_list))\n",
    "                turns['dur'].append(track.words[end].end - track.words[strt].beg)\n",
    "                turns['word_max'].append(max([word.dur for word in word_list]))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue      \n",
    "    \n",
    "    return pd.DataFrame(turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03ac4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b942bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Speaker s01 (f, y)>\n",
      "<Speaker s02 (f, o)>\n",
      "<Speaker s03 (m, o)>\n",
      "<Speaker s04 (f, y)>\n",
      "<Speaker s05 (f, o)>\n",
      "<Speaker s06 (m, y)>\n",
      "No Match\n",
      "<Speaker s07 (f, o)>\n",
      "No Match\n",
      "<Speaker s08 (f, y)>\n",
      "No Match\n",
      "<Speaker s09 (f, y)>\n",
      "<Speaker s10 (m, o)>\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "<Speaker s11 (m, y)>\n",
      "No Match\n",
      "<Speaker s12 (f, y)>\n",
      "<Speaker s13 (m, y)>\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "<Speaker s14 (f, o)>\n",
      "<Speaker s15 (m, y)>\n",
      "No Match\n",
      "<Speaker s16 (f, o)>\n",
      "No Match\n",
      "<Speaker s17 (f, o)>\n",
      "<Speaker s18 (f, o)>\n",
      "No Match\n",
      "list index out of range\n",
      "<Speaker s19 (m, o)>\n",
      "list index out of range\n",
      "<Speaker s20 (f, o)>\n",
      "<Speaker s21 (f, y)>\n",
      "<Speaker s22 (m, o)>\n",
      "<Speaker s23 (m, o)>\n",
      "<Speaker s24 (m, o)>\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "<Speaker s25 (f, o)>\n",
      "<Speaker s26 (f, y)>\n",
      "<Speaker s27 (f, o)>\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "<Speaker s28 (m, y)>\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "<Speaker s29 (m, o)>\n",
      "list index out of range\n",
      "No Match\n",
      "list index out of range\n",
      "list index out of range\n",
      "<Speaker s30 (m, y)>\n",
      "<Speaker s31 (f, y)>\n",
      "<Speaker s32 (m, y)>\n",
      "list index out of range\n",
      "<Speaker s33 (m, y)>\n",
      "<Speaker s34 (m, y)>\n",
      "<Speaker s35 (m, o)>\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "No Match\n",
      "<Speaker s36 (m, o)>\n",
      "No Match\n",
      "<Speaker s37 (f, y)>\n",
      "No Match\n",
      "list index out of range\n",
      "<Speaker s38 (m, o)>\n",
      "<Speaker s39 (f, y)>\n",
      "No Match\n",
      "list index out of range\n",
      "<Speaker s40 (m, y)>\n",
      "list index out of range\n",
      "list index out of range\n",
      "No Match\n",
      "No Match\n"
     ]
    }
   ],
   "source": [
    "track_segs = []\n",
    "corpus = buckeye.corpus('/mnt/cube/Datasets/buckeye_zips/', load_wavs = True)\n",
    "\n",
    "for speaker in corpus:\n",
    "    print(speaker)\n",
    "    track_id = 0\n",
    "    for track in speaker:\n",
    "        #print(track)\n",
    "        track_df = turn_segments(track)\n",
    "        track_df['speaker'] = speaker.name\n",
    "        track_df['track'] = track.name\n",
    "        track_df['track_id'] = track_id\n",
    "        track_segs.append(track_df)\n",
    "        \n",
    "        track_id += 1\n",
    "        \n",
    "track_segs = pd.concat(track_segs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43abeacf",
   "metadata": {},
   "source": [
    "## Sort through turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16dbd898",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_turns = track_segs[\n",
    "    (track_segs.dur > 16.855625) & ## within anna's range\n",
    "    (track_segs.dur < 77.089875) & ## within anna's range\n",
    "    (track_segs.utt > 10) & ## make sure there are enough tokens in the turn\n",
    "    (track_segs.word_max < 2) ## max word length isn't over 2 sec\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df7d3e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>strt</th>\n",
       "      <th>strt_t</th>\n",
       "      <th>end</th>\n",
       "      <th>end_t</th>\n",
       "      <th>utt</th>\n",
       "      <th>dur</th>\n",
       "      <th>word_max</th>\n",
       "      <th>speaker</th>\n",
       "      <th>track</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>um i'm a um &lt;VOCNOISE&gt; &lt;SIL&gt; it's kind of a un...</td>\n",
       "      <td>40</td>\n",
       "      <td>56.598353</td>\n",
       "      <td>142</td>\n",
       "      <td>84.512061</td>\n",
       "      <td>103</td>\n",
       "      <td>27.913708</td>\n",
       "      <td>1.435416</td>\n",
       "      <td>s01</td>\n",
       "      <td>s0101a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>um &lt;VOCNOISE&gt; working on three different &lt;SIL&gt;...</td>\n",
       "      <td>144</td>\n",
       "      <td>90.457150</td>\n",
       "      <td>214</td>\n",
       "      <td>110.163138</td>\n",
       "      <td>71</td>\n",
       "      <td>19.705988</td>\n",
       "      <td>0.788701</td>\n",
       "      <td>s01</td>\n",
       "      <td>s0101a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a nurse practitioner has more authority i gues...</td>\n",
       "      <td>270</td>\n",
       "      <td>144.551487</td>\n",
       "      <td>350</td>\n",
       "      <td>168.275562</td>\n",
       "      <td>81</td>\n",
       "      <td>23.724075</td>\n",
       "      <td>0.813652</td>\n",
       "      <td>s01</td>\n",
       "      <td>s0101a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yes &lt;VOCNOISE&gt; i uh &lt;SIL&gt; um &lt;SIL&gt; uh &lt;VOCNOIS...</td>\n",
       "      <td>441</td>\n",
       "      <td>225.267180</td>\n",
       "      <td>532</td>\n",
       "      <td>247.699562</td>\n",
       "      <td>92</td>\n",
       "      <td>22.432382</td>\n",
       "      <td>0.855013</td>\n",
       "      <td>s01</td>\n",
       "      <td>s0101a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>for me personally &lt;SIL&gt; um &lt;SIL&gt; family being ...</td>\n",
       "      <td>540</td>\n",
       "      <td>266.802112</td>\n",
       "      <td>659</td>\n",
       "      <td>299.150227</td>\n",
       "      <td>120</td>\n",
       "      <td>32.348115</td>\n",
       "      <td>1.640866</td>\n",
       "      <td>s01</td>\n",
       "      <td>s0101a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  strt      strt_t  end  \\\n",
       "1  um i'm a um <VOCNOISE> <SIL> it's kind of a un...    40   56.598353  142   \n",
       "2  um <VOCNOISE> working on three different <SIL>...   144   90.457150  214   \n",
       "5  a nurse practitioner has more authority i gues...   270  144.551487  350   \n",
       "8  yes <VOCNOISE> i uh <SIL> um <SIL> uh <VOCNOIS...   441  225.267180  532   \n",
       "9  for me personally <SIL> um <SIL> family being ...   540  266.802112  659   \n",
       "\n",
       "        end_t  utt        dur  word_max speaker   track  track_id  \n",
       "1   84.512061  103  27.913708  1.435416     s01  s0101a         0  \n",
       "2  110.163138   71  19.705988  0.788701     s01  s0101a         0  \n",
       "5  168.275562   81  23.724075  0.813652     s01  s0101a         0  \n",
       "8  247.699562   92  22.432382  0.855013     s01  s0101a         0  \n",
       "9  299.150227  120  32.348115  1.640866     s01  s0101a         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_turns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c71d9596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ee0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_turns.to_pickle('/mnt/cube/j8xing/buckeye_ser/data/interim/candidate_turns.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a4e7f2",
   "metadata": {},
   "source": [
    "## Save Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e3e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5009146e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1132it [14:50,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(valid_turns.iterrows()):\n",
    "    if i > 10:\n",
    "        pass\n",
    "    speaker = buckeye.Speaker.from_zip(f'/mnt/cube/Datasets/buckeye_zips/{row.speaker}.zip', load_wavs = True)\n",
    "    speaker[row.track_id].clip_wav(\n",
    "        f'/mnt/cube/j8xing/buckeye_ser/data/interim/buckeye_candidates/{row.track}_{row.strt}_{row.end}.wav', \n",
    "        row.strt_t, \n",
    "        row.end_t\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ser",
   "language": "python",
   "name": "ser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
